Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Losses/Value Loss,Losses/Policy Loss,Policy/Learning Rate,Policy/Epsilon,Policy/Beta,Is Training
50000,1.4150165,24.18992443324937,-0.113683,1.419052360429158,1.419052360429158,0.3598508,0.025469955,0.0002846139,0.1948713,0.0047440785,1.0
100000,1.4059199,29.633802816901408,0.47383773,1.9629515392314563,1.9629515392314563,0.2164317,0.025494596,0.00025693933,0.18564644,0.004283757,1.0
150000,1.3900182,37.850699844479,0.85602325,2.784459957686523,2.784459957686523,0.44879395,0.025145108,0.00022618085,0.17539361,0.003772141,1.0
200000,1.37391,54.11233480176212,1.3724673,4.4133408029523675,4.4133408029523675,0.73963505,0.023950126,0.0001953898,0.16512993,0.0032599834,1.0
